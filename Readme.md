# Building Multimodal Corpora Using Whisper, spaCy and CQPweb

## Abstract
This paper introduces a workflow for building multimodal corpora, addressing challenges in transcription, alignment, and linguistic analysis across audio, text, and visual data. Unlike traditional text corpora, multimodal corpora enable insights into how language interacts with acoustic and visual cues, which is essential for understanding communication in its full complexity. The approach integrates Whisper and whisperX for multilingual transcription and word-level timestamp accuracy, spaCy for natural language processing, and CQPweb for corpus management and analysis, creating a scalable pipeline for multimodal data.

A case study uses the NewsScape 2017 Corpus, a large audiovisual dataset from U.S. news media. This example illustrates the pipeline’s ability to retrieve multimodal results from text-based queries, enabling exploration of linguistic patterns alongside synchronized video content and laying groundwork for extensions into visual data analysis with tools such as OpenPose. By enabling analysis of co-occurring verbal and non-verbal features, this workflow offers a resource for multimodal studies in linguistics, cognitive science, and computational analysis, bridging audio and visual modalities to advance the study of language in its full communicative context.

## Authors
- Raúl Sánchez <raul@um.es>, University of Murcia  
- Rosa Illán Castillo <mariarosario.illan@um.es>, Laboratoire Dynamique du Langage, Lyon  
- Peter Uhrig <peter.uhrig@fau.de>, Friedrich-Alexander University Erlangen-Nürnberg  
- Cristóbal Pagán <cpcanovas@um.es>, University of Murcia  

## Purpose
This repository provides example scripts, mapping tables, and reference snippets that illustrate parts of the workflow described in the paper. It does not repeat the full explanations; refer to the paper for details on design choices and steps.

No step-by-step instructions are repeated here; the paper contains the detailed process.

## Contact
For questions about the examples or the paper, contact the authors listed above.
